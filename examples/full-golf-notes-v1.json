{"{\"NSuccesses\":\"binomial\",\"PSuccess\":\"logistic\"}":["Model #1","From Andrew Gelman's case study: https://mc-stan.org/users/documentation/case-studies/golf.html\n\nGiven usual statistical practice, the natural starting point would be logistic regression like this model.\n\nThe code in the model block is (implicitly) vectorized, so that it is mathematically equivalent to modeling each data point, y[i] ~ binomial_logit(n[i], a + b*x[i]). The vectorized code is more compact (no need to write a loop, or to include the subscripts) and faster (because of more efficient gradient evaluations).\n\nHere is the result:\nInference for Stan model: golf_logistic.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n   mean se_mean   sd   25%   50%   75% n_eff Rhat\na  2.23       0 0.06  2.19  2.23  2.27  1157    1\nb -0.26       0 0.01 -0.26 -0.26 -0.25  1170    1\n\nSamples were drawn using NUTS(diag_e) at Tue Oct  1 15:56:33 2019.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n"],"{\"NSuccesses\":\"binomial\",\"PAngleSuccess\":\"angle_success\",\"PSuccess\":\"angle_only\"}":["Model #2","From Andrew Gelman's case study: https://mc-stan.org/users/documentation/case-studies/golf.html\n\nAs an alternative to logistic regression, we shall build a model from first principles and fit it to the data.\n\nThe graph below (see case study) shows a simplified sketch of a golf shot. The dotted line represents the angle within which the ball of radius r must be hit so that it falls within the hole of radius R. This threshold angle is sin−1((R−r)/x). The graph, which is not to scale, is intended to illustrate the geometry of the ball needing to go into the hole.\n\nThe next step is to model human error. We assume that the golfer is attempting to hit the ball completely straight but that many small factors interfere with this goal, so that the actual angle follows a normal distribution centered at 0 with some standard deviation σ.\n\nThe probability the ball goes in the hole is then the probability that the angle is less than the threshold; that is, Pr(|angle|<sin−1((R−r)/x))=2Φ(sin−1((R−r)/x)σ)−1, where Φ is the cumulative normal distribution function. The only unknown parameter in this model is σ, the standard deviation of the distribution of shot angles. Stan (and, for that matter, R) computes trigonometry using angles in radians, so at the end of our calculations we will need to multiply by 180/π to convert to degrees, which are more interpretable by humans.\n\nThe highest curve on the graph corresponds to σ=0.5∘: if golfers could control the angles of their putts to an accuracy of approximately half a degree, they would have a very high probability of success, making over 80% of their ten-foot putts, over 50% of their fifteen-foot putts, and so on. At the other extreme, the lowest plotted curve corresponds to σ=20∘: if your putts could be off as high as 20 degrees, then you would be highly inaccurate, missing more than half of your two-foot putts. When fitting the model in Stan, the program moves around the space of σ, sampling from the posterior distribution.\n\nHere is the result:\n\nInference for Stan model: golf_angle.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n              mean se_mean   sd  25%  50%  75% n_eff Rhat\nsigma         0.03       0 0.00 0.03 0.03 0.03  1674    1\nsigma_degrees 1.53       0 0.02 1.51 1.53 1.54  1674    1\n\nSamples were drawn using NUTS(diag_e) at Tue Oct  1 15:57:15 2019.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\nThe model has a single parameter, σ. From the output, we find that Stan has computed the posterior mean of σ to be 0.03. Multiplying this by 180/π, this comes to 1.53 degrees. The Monte Carlo standard error of the mean is 0 (to two decimal places), indicating that the simulations have run long enough to estimate the posterior mean precisely. The posterior standard deviation is calculated at 0.02 degrees, indicating that σ itself has been estimated with high precision, which makes sense given the large number of data points and the simplicity of the model. The precise posterior distribution of σ can also be seen from the narrow range of the posterior quantiles. Finally, Rˆ is near 1, telling us that the simulations from Stan’s four simulated chains have mixed well.\n\nThis custom nonlinear model fits the data much better. This is not to say that the model is perfect—any experience of golf will reveal that the angle is not the only factor determining whether the ball goes in the hole—but it seems like a useful start, and it is good to know that we can fit nonlinear models by just coding them up in Stan.\n"],"{\"NSuccesses\":\"binomial\",\"OvershootModel\":\"fixed\",\"PAngleSuccess\":\"angle_success\",\"PDistanceSuccess\":\"distance_success\",\"PSuccess\":\"angle_and_distance\"}":["Model #3","From Andrew Gelman's case study: https://mc-stan.org/users/documentation/case-studies/golf.html\n\nTo get the ball in the hole, the angle isn’t the only thing you need to control; you also need to hit the ball just hard enough.\n\nMark Broadie added this to our model by introducing another parameter corresponding to the golfer’s control over distance. Supposing u is the distance that golfer’s shot would travel if there were no hole, Broadie assumes that the putt will go in if (a) the angle allows the ball to go over the hole, and (b) u is in the range [x,x+3]. That is the ball must be hit hard enough to reach the whole but not go too far. Factor (a) is what we have considered earlier; we must now add factor (b).\n\nBroadie supposes that a golfer will aim to hit the ball one foot past the hole but with a multiplicative error in the shot’s potential distance, so that u=(x+1)⋅(1+error), where the error has a normal distribution with mean 0 and standard deviation σdistance. This new parameter σdistance represents the uncertainty in the shot’s relative distance. In statistics notation, this model is, u∼normal(x+1,(x+1)σ_distance), and the distance is acceptable if u∈[x,x+3], an event that has probability Φ(2(x+1)σ_distance)−Φ(−1(x+1)σ_distance).\n\nWe might wonder why if the distance range is 3 feet, the overshot is not 1.5 feet. One reason could be that it is riskier to hit the ball too hard than too soft. In addition we assigned weakly informative half-normal(0,1) priors on the scale parameters, σangle and σdistance, which are required in this case to keep the computations stable.\n\nThere is poor convergence, and we need to figure out what is going on here. (Problems with computation often indicate underlying problems with the model being fit. That’s the folk theorem of statistical computing.)\n\nInference for Stan model: golf_angle_distance_2.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n               mean se_mean   sd  25%  50%  75% n_eff  Rhat\nsigma_angle    0.01    0.00 0.00 0.01 0.01 0.01     2 15.70\nsigma_distance 0.13    0.01 0.02 0.13 0.14 0.14     2 41.78\nsigma_degrees  0.86    0.11 0.16 0.76 0.76 0.84     2 15.70\n\nSamples were drawn using NUTS(diag_e) at Tue Oct  1 15:57:54 2019.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n"],"{\"NSuccesses\":\"proportional\",\"OvershootModel\":\"fixed\",\"PAngleSuccess\":\"angle_success\",\"PDistanceSuccess\":\"distance_success\",\"PSuccess\":\"angle_and_distance\"}":["Model #4","From Andrew Gelman's case study: https://mc-stan.org/users/documentation/case-studies/golf.html\n\nWith such large values of nj, the binomial likelihood enforces an extremely close fit at these first few points, and that drives the entire fit of the model.\n\nTo fix this problem we took the data model, yj∼binomial(nj,pj), and added an independent error term to each observation. There is no easy way to add error directly to the binomial distribution—we could replace it with its overdispersed generalization, the beta-binomial, but this would not be appropriate here because the variance for each data point i would still be roughly proportional to the sample size nj, and our whole point here is to get away from this assumption and allow for model misspecification—so instead we first approximate the binomial data distribution by a normal and then add independent variance; thus:\ny_j/n_j∼normal(p_j,sqrt(p_j(1−p_j)/n_j+σ_y^2)).\n\nTo write this in Stan there are some complications:\n\n * y and n are integer variables, which we convert to vectors so that we can multiply and divide them.\n\n * To perform componentwise multiplication or division using vectors, you need to use .* or ./ so that San knows not to try to perform vector/matrix multiplication and division. Stan is opposite from R in this way: Stan defaults to vector/matrix operations and has to be told otherwise, whereas R defaults to componentwise operations, and vector/matrix multiplication in R is indicated using the %*% operator.\n \nTo complete the model we add σy to the parameters block and assign it a weakly informative half-normal(0,1) prior distribution. \n\nWe now fit this model to the data:\n\nInference for Stan model: golf_angle_distance_3.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n                mean se_mean    sd   25%   50%   75% n_eff  Rhat\nsigma_angle    0.018       0 0.000 0.018 0.018 0.018  1526 1.004\nsigma_distance 0.080       0 0.001 0.079 0.080 0.081  1540 1.005\nsigma_y        0.003       0 0.001 0.003 0.003 0.003  2002 1.001\nsigma_degrees  1.020       0 0.006 1.016 1.020 1.024  1526 1.004\n\nSamples were drawn using NUTS(diag_e) at Tue Oct  1 15:58:35 2019.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nThe new parameter estimates are:\n\n * σ_angle is estimated at 0.02, which when corresponds to σdegrees= 1.0. According to the fitted model, there is a standard deviation of 1.0 degree in the angles of putts taken by pro golfers. The estimate of σangle has decreased compared to the earlier model that only had angular errors. This makes sense: now that distance errors have been included in the model, there is no need to explain so many of the missed shots using errors in angle.\n\n * σ_distance is estimated at 0.08. According to the fitted model, there is a standard deviation of 8% in the errors of distance.\n\n * σ_y is estimated at 0.003. The fitted model fits the aggregate data (success rate as a function of distance) to an accuracy of 0.3 percentage points.\n \nThe residuals are small (see the scale of the y-axis) and show no clear pattern, suggesting not that the model is perfect but that there are no clear ways to develop it further just given the current data.\n\n\n"],"{\"NSuccesses\":\"proportional\",\"OvershootModel\":\"parametric\",\"PAngleSuccess\":\"angle_success\",\"PDistanceSuccess\":\"distance_success\",\"PSuccess\":\"angle_and_distance\"}":["Model #5","From Andrew Gelman's case study: https://mc-stan.org/users/documentation/case-studies/golf.html\n\nThe model has two parameters that were fixed as data: distance_tolerance, which was set to 3 (implying that the ball will only fall into the hole if it is hit on a trajectory that would go past the hole, but no more than 3 feet past) and overshot, which was set to 1 (implying that the golfer will aim 1 foot past the hole). In theory it would be possible to estimate either or both these parameters from the data. In practice, no way. The model already fits the data so well (as shown by the above graph) that there’s clearly no more information available to estimate any additional parameters. If we were to do so, the estimates would be highly noisy and unstable (if their prior is weak) or highly dependent on the prior (if an informative prior distribution is specified). Either way we don’t see the advantage of this sort of fit.\n\nJust for laughs, though, we constructed such a model and fit it, just to see what would happen. We simply took our previous Stan program and moved these two parameters from the data block to the parameters block along with zero-boundary constraints.\n\nFitting this model to the data yields poor convergence and no real gain beyond the simpler version already fit in which overshot and distance_tolerance were set to fixed values."]}